{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T07:58:22.239825Z",
     "iopub.status.busy": "2025-01-08T07:58:22.239513Z",
     "iopub.status.idle": "2025-01-08T07:58:46.287280Z",
     "shell.execute_reply": "2025-01-08T07:58:46.286420Z",
     "shell.execute_reply.started": "2025-01-08T07:58:22.239799Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
      "Collecting opendatasets\n",
      "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.5)\n",
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.6.17)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.2.3)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.10)\n",
      "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: opendatasets\n",
      "Successfully installed opendatasets-0.1.22\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.44.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.7)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-3.3.1\n",
      "Collecting resampy\n",
      "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from resampy) (1.26.4)\n",
      "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.10/dist-packages (from resampy) (0.60.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.53->resampy) (0.43.0)\n",
      "Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: resampy\n",
      "Successfully installed resampy-0.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown\n",
    "!pip install transformers\n",
    "!pip install opendatasets\n",
    "!pip install pydub\n",
    "!pip install gdown\n",
    "!pip install -U sentence-transformers\n",
    "!pip install resampy\n",
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "!pip install nltk\n",
    "!pip install tabulate\n",
    "!pip install librosa\n",
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install opencv-python\n",
    "!pip install datasets\n",
    "!pip install torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T07:58:46.288743Z",
     "iopub.status.busy": "2025-01-08T07:58:46.288511Z",
     "iopub.status.idle": "2025-01-08T07:59:00.433948Z",
     "shell.execute_reply": "2025-01-08T07:59:00.433269Z",
     "shell.execute_reply.started": "2025-01-08T07:58:46.288716Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import resampy\n",
    "from transformers import AutoProcessor, Wav2Vec2Model\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "import opendatasets as od\n",
    "import pandas as pd\n",
    "import gc\n",
    "import random\n",
    "import pickle\n",
    "import gdown\n",
    "import json\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "from zipfile import ZipFile\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms.functional as F\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from IPython.display import FileLink\n",
    "from shutil import rmtree\n",
    "from datasets import load_dataset\n",
    "from IPython.display import Audio, display\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T07:59:00.435674Z",
     "iopub.status.busy": "2025-01-08T07:59:00.435024Z",
     "iopub.status.idle": "2025-01-08T07:59:00.491764Z",
     "shell.execute_reply": "2025-01-08T07:59:00.490933Z",
     "shell.execute_reply.started": "2025-01-08T07:59:00.435649Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:25:21.091824Z",
     "iopub.status.busy": "2025-01-08T08:25:21.091462Z",
     "iopub.status.idle": "2025-01-08T08:25:26.361720Z",
     "shell.execute_reply": "2025-01-08T08:25:26.360842Z",
     "shell.execute_reply.started": "2025-01-08T08:25:21.091794Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1RSB9tOrbf0PLGAAVYx2Z4odRnWeAp8rS\n",
      "To: /kaggle/working/clasp.pt\n",
      "100%|██████████| 25.4M/25.4M [00:00<00:00, 154MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'clasp.pt'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://drive.google.com/file/d/1RSB9tOrbf0PLGAAVYx2Z4odRnWeAp8rS/view?usp=sharing\"\n",
    "output = \"clasp.pt\"\n",
    "gdown.download(url, output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:25:26.363138Z",
     "iopub.status.busy": "2025-01-08T08:25:26.362817Z",
     "iopub.status.idle": "2025-01-08T08:25:31.124767Z",
     "shell.execute_reply": "2025-01-08T08:25:31.123879Z",
     "shell.execute_reply.started": "2025-01-08T08:25:26.363097Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1hXe01KlK6JUA62A3rIFAl-xwuF0Q9A4T\n",
      "From (redirected): https://drive.google.com/uc?id=1hXe01KlK6JUA62A3rIFAl-xwuF0Q9A4T&confirm=t&uuid=314b61f8-ef7a-4304-b3df-60f3fb59c929\n",
      "To: /kaggle/working/sample_data.zip\n",
      "100%|██████████| 34.6M/34.6M [00:00<00:00, 50.0MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sample_data.zip'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://drive.google.com/file/d/1hXe01KlK6JUA62A3rIFAl-xwuF0Q9A4T/view?usp=sharing\"\n",
    "output = \"sample_data.zip\"\n",
    "gdown.download(url, output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:25:31.126068Z",
     "iopub.status.busy": "2025-01-08T08:25:31.125861Z",
     "iopub.status.idle": "2025-01-08T08:25:31.387722Z",
     "shell.execute_reply": "2025-01-08T08:25:31.386786Z",
     "shell.execute_reply.started": "2025-01-08T08:25:31.126049Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with ZipFile('sample_data.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('samples-brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:27:00.607617Z",
     "iopub.status.busy": "2025-01-08T08:27:00.607254Z",
     "iopub.status.idle": "2025-01-08T08:27:00.619393Z",
     "shell.execute_reply": "2025-01-08T08:27:00.618689Z",
     "shell.execute_reply.started": "2025-01-08T08:27:00.607585Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 45254,\n",
       "  'file_path': 'dataset/part9/audios/audio_45254.wav',\n",
       "  'text': 'Morgan hesitated , thinking that if this was a trick , it was a good one.',\n",
       "  'category': 'adventure'},\n",
       " {'id': 45255,\n",
       "  'file_path': 'dataset/part9/audios/audio_45255.wav',\n",
       "  'text': \"He didn't think it was possible for this couple to be pretending.\",\n",
       "  'category': 'adventure'},\n",
       " {'id': 45256,\n",
       "  'file_path': 'dataset/part9/audios/audio_45256.wav',\n",
       "  'text': 'The boy licked his dry lips.',\n",
       "  'category': 'adventure'},\n",
       " {'id': 45257,\n",
       "  'file_path': 'dataset/part9/audios/audio_45257.wav',\n",
       "  'text': \"He asked , `` Could we have a drink ''??\",\n",
       "  'category': 'adventure'},\n",
       " {'id': 19424,\n",
       "  'file_path': 'dataset/part4/audios/audio_19424.wav',\n",
       "  'text': 'In business circles , usually conservative , this sort of atmosphere would hardly be found.',\n",
       "  'category': 'belles_lettres'},\n",
       " {'id': 19425,\n",
       "  'file_path': 'dataset/part4/audios/audio_19425.wav',\n",
       "  'text': 'But in our case -- and neither my wife nor I have extreme views on integration , nor are we given to emotional outbursts -- the situation has ruined one or two valued friendships and come close to wrecking several more.',\n",
       "  'category': 'belles_lettres'},\n",
       " {'id': 19426,\n",
       "  'file_path': 'dataset/part4/audios/audio_19426.wav',\n",
       "  'text': 'Accounts have been published of Northern liberals in the South up against segregationist prejudice , especially in state-supported universities where pressure may be strong to uphold the majority view.',\n",
       "  'category': 'belles_lettres'},\n",
       " {'id': 19427,\n",
       "  'file_path': 'dataset/part4/audios/audio_19427.wav',\n",
       "  'text': 'But these accounts do not show that Northerners have been subjected to embarrassment or provocation by Yankee-hatred displayed in social gatherings.',\n",
       "  'category': 'belles_lettres'},\n",
       " {'id': 4515,\n",
       "  'file_path': 'dataset/part1/audios/audio_4515.wav',\n",
       "  'text': 'The Rusk belief in balanced defense , replacing the Dulles theory of massive retaliation , removes a grave danger that has existed.',\n",
       "  'category': 'editorial'},\n",
       " {'id': 4516,\n",
       "  'file_path': 'dataset/part1/audios/audio_4516.wav',\n",
       "  'text': \"The danger lay not in believing that our own A-bombs would deter Russia's use of hers ; ;\",\n",
       "  'category': 'editorial'},\n",
       " {'id': 4517,\n",
       "  'file_path': 'dataset/part1/audios/audio_4517.wav',\n",
       "  'text': 'that theory was and is sound.',\n",
       "  'category': 'editorial'},\n",
       " {'id': 4518,\n",
       "  'file_path': 'dataset/part1/audios/audio_4518.wav',\n",
       "  'text': 'The danger lay in the American delusion that nuclear deterrence was enough.',\n",
       "  'category': 'editorial'},\n",
       " {'id': 36297,\n",
       "  'file_path': 'dataset/part7/audios/audio_36297.wav',\n",
       "  'text': 'Rachel had little to say.',\n",
       "  'category': 'fiction'},\n",
       " {'id': 36298,\n",
       "  'file_path': 'dataset/part7/audios/audio_36298.wav',\n",
       "  'text': \"She greeted her husband's colleagues with smiling politeness , offering nothing.\",\n",
       "  'category': 'fiction'},\n",
       " {'id': 36299,\n",
       "  'file_path': 'dataset/part7/audios/audio_36299.wav',\n",
       "  'text': \"Mr. McKinley , for all his sprawling and his easy familiarity , was completely alert to his son , eyes always on the still face , jumping to anticipate Scotty's desires.\",\n",
       "  'category': 'fiction'},\n",
       " {'id': 36300,\n",
       "  'file_path': 'dataset/part7/audios/audio_36300.wav',\n",
       "  'text': 'It was a strained , silent lunch.',\n",
       "  'category': 'fiction'},\n",
       " {'id': 26180,\n",
       "  'file_path': 'dataset/part5/audios/audio_26180.wav',\n",
       "  'text': 'Production assistance often takes the form of locating tools or materials which are urgently needed.',\n",
       "  'category': 'government'},\n",
       " {'id': 26181,\n",
       "  'file_path': 'dataset/part5/audios/audio_26181.wav',\n",
       "  'text': 'Advice is given also on problems of plant location and plant space.',\n",
       "  'category': 'government'},\n",
       " {'id': 26182,\n",
       "  'file_path': 'dataset/part5/audios/audio_26182.wav',\n",
       "  'text': 'Property sales assistance',\n",
       "  'category': 'government'},\n",
       " {'id': 26183,\n",
       "  'file_path': 'dataset/part5/audios/audio_26183.wav',\n",
       "  'text': 'The property sales assistance program is designed to assist small business concerns that may wish to buy property offered for sale by the Federal Government.',\n",
       "  'category': 'government'},\n",
       " {'id': 10670,\n",
       "  'file_path': 'dataset/part2/audios/audio_10670.wav',\n",
       "  'text': 'As you can see , in this Push-Pull Super Set the entire chest-back-shoulder area is vigorously exercised in alternate sectors by alternate exercises so the complete torso remains pumped-up all the time!!',\n",
       "  'category': 'hobbies'},\n",
       " {'id': 10671,\n",
       "  'file_path': 'dataset/part2/audios/audio_10671.wav',\n",
       "  'text': 'Now when Henri has completed four complete Push-Pull Super-Sets No. 1 , the professor allows him about a five-minute rest period before starting him on four complete Push-Pull Super-Sets No. 2.',\n",
       "  'category': 'hobbies'},\n",
       " {'id': 10672,\n",
       "  'file_path': 'dataset/part2/audios/audio_10672.wav',\n",
       "  'text': \"Super-Set No. 2 is made up of similar exercises , but this time done with dumbbells , and using both `` moon '' and flat benches.\",\n",
       "  'category': 'hobbies'},\n",
       " {'id': 10673,\n",
       "  'file_path': 'dataset/part2/audios/audio_10673.wav',\n",
       "  'text': \"The `` push '' exercise of this Push-Pull Super-Set is the Bench Press done with elbows well pulled back and with a greater downward stretch of the pectorals not possible with the barbell variation.\",\n",
       "  'category': 'hobbies'},\n",
       " {'id': 54200,\n",
       "  'file_path': 'dataset/part10/audios/audio_54200.wav',\n",
       "  'text': \"But to Welch's chagrin , the police captain pooh-poohed Welch's credulity in Barco's confession.\",\n",
       "  'category': 'humor'},\n",
       " {'id': 54201,\n",
       "  'file_path': 'dataset/part10/audios/audio_54201.wav',\n",
       "  'text': \"Barco was clearly a `` nut ''.\",\n",
       "  'category': 'humor'},\n",
       " {'id': 54202,\n",
       "  'file_path': 'dataset/part10/audios/audio_54202.wav',\n",
       "  'text': 'It required strength , bravado , daring to commit murder.',\n",
       "  'category': 'humor'},\n",
       " {'id': 54203,\n",
       "  'file_path': 'dataset/part10/audios/audio_54203.wav',\n",
       "  'text': '`` That worm a murderer??',\n",
       "  'category': 'humor'},\n",
       " {'id': 28970,\n",
       "  'file_path': 'dataset/part6/audios/audio_28970.wav',\n",
       "  'text': 'There have been few measurements specifically for the determination of the polarization of planetary radiation.',\n",
       "  'category': 'learned'},\n",
       " {'id': 28971,\n",
       "  'file_path': 'dataset/part6/audios/audio_28971.wav',\n",
       "  'text': 'The measurements made with the NRL 50-foot reflector , which is altitude-azimuth-mounted , would have shown a systematic change with local hour angle in the measured intensities of Venus and Jupiter if a substantial part of the radiation had been linearly polarized.',\n",
       "  'category': 'learned'},\n",
       " {'id': 28972,\n",
       "  'file_path': 'dataset/part6/audios/audio_28972.wav',\n",
       "  'text': 'Recent interferometer measurements ( Radhakrishnan and Roberts , 1960 ) have shown the 960-mc emission of Jupiter to be partially polarized and to originate in a region of larger diameter than the visible disk.',\n",
       "  'category': 'learned'},\n",
       " {'id': 28973,\n",
       "  'file_path': 'dataset/part6/audios/audio_28973.wav',\n",
       "  'text': 'Other than this very significant result , most of the information now available about the radio emission of the planets is restricted to the intensity of the radiation.',\n",
       "  'category': 'learned'},\n",
       " {'id': 14758,\n",
       "  'file_path': 'dataset/part3/audios/audio_14758.wav',\n",
       "  'text': 'Since interviewing is the basic therapeutic and diagnostic instrument of modern psychiatry , the recording of interviews for playbacks and study has been a boost of Redstone proportions in new research and training.',\n",
       "  'category': 'lore'},\n",
       " {'id': 14759,\n",
       "  'file_path': 'dataset/part3/audios/audio_14759.wav',\n",
       "  'text': 'At a minimum , recording -- usually on tape , which is now in wide professional use -- brings the psychiatric interview alive so that the full range of emotion and meaning can be explored repeatedly by the therapist or by a battery of therapists.',\n",
       "  'category': 'lore'},\n",
       " {'id': 14760,\n",
       "  'file_path': 'dataset/part3/audios/audio_14760.wav',\n",
       "  'text': 'Newest to this high-powered battery are the experts in linguistics who have carried that minimum to a new level.',\n",
       "  'category': 'lore'},\n",
       " {'id': 14761,\n",
       "  'file_path': 'dataset/part3/audios/audio_14761.wav',\n",
       "  'text': 'By adding a systematic analysis with symbols to the typed transcripts of interviews , they have supplied a new set of techniques for the therapist.',\n",
       "  'category': 'lore'},\n",
       " {'id': 40461,\n",
       "  'file_path': 'dataset/part8/audios/audio_40461.wav',\n",
       "  'text': '`` Why should I??',\n",
       "  'category': 'mystery'},\n",
       " {'id': 40462,\n",
       "  'file_path': 'dataset/part8/audios/audio_40462.wav',\n",
       "  'text': \"I've worked this ward for three months now.\",\n",
       "  'category': 'mystery'},\n",
       " {'id': 40463,\n",
       "  'file_path': 'dataset/part8/audios/audio_40463.wav',\n",
       "  'text': 'We keep getting the same ones back again and again.',\n",
       "  'category': 'mystery'},\n",
       " {'id': 40464,\n",
       "  'file_path': 'dataset/part8/audios/audio_40464.wav',\n",
       "  'text': 'They all mean well , have great promises to make when they are about to go home , but drinking is their sickness.',\n",
       "  'category': 'mystery'},\n",
       " {'id': 32,\n",
       "  'file_path': 'dataset/part1/audios/audio_32.wav',\n",
       "  'text': 'The couple was married Aug. 2 , 1913.',\n",
       "  'category': 'news'},\n",
       " {'id': 33,\n",
       "  'file_path': 'dataset/part1/audios/audio_33.wav',\n",
       "  'text': 'They have a son , William Berry Jr. , and a daughter , Mrs. J. M. Cheshire of Griffin.',\n",
       "  'category': 'news'},\n",
       " {'id': 34,\n",
       "  'file_path': 'dataset/part1/audios/audio_34.wav',\n",
       "  'text': 'Attorneys for the mayor said that an amicable property settlement has been agreed upon.',\n",
       "  'category': 'news'},\n",
       " {'id': 35,\n",
       "  'file_path': 'dataset/part1/audios/audio_35.wav',\n",
       "  'text': \"The petition listed the mayor's occupation as `` attorney '' and his age as 71.\",\n",
       "  'category': 'news'},\n",
       " {'id': 9087,\n",
       "  'file_path': 'dataset/part2/audios/audio_9087.wav',\n",
       "  'text': 'Instead , the audience can sit back at ease and , from the perspective of an enlightened time which no longer believes in such things , enjoy the dead seriousness with which the characters in the play take the witches and devils which are under discussion.',\n",
       "  'category': 'religion'},\n",
       " {'id': 9088,\n",
       "  'file_path': 'dataset/part2/audios/audio_9088.wav',\n",
       "  'text': 'A teenage girl , Abigail Williams , is being sharply questioned by her minister uncle , the Reverend Samuel Parris , about a wild night affair in the woods in which she and some other girls had seemed to have had contact with these evil beings.',\n",
       "  'category': 'religion'},\n",
       " {'id': 9089,\n",
       "  'file_path': 'dataset/part2/audios/audio_9089.wav',\n",
       "  'text': 'For all involved in this discussion the devil is a real entity who can really be confronted in the woods on a dark night , the demon world is populated with real creatures , and witches actually can be seen flying through the air.',\n",
       "  'category': 'religion'},\n",
       " {'id': 9090,\n",
       "  'file_path': 'dataset/part2/audios/audio_9090.wav',\n",
       "  'text': 'As the play unfolds , however , the audience is subtly brought into the grip of an awful evil which grows with ominously gathering power and soon engulfs the community.',\n",
       "  'category': 'religion'},\n",
       " {'id': 7413,\n",
       "  'file_path': 'dataset/part2/audios/audio_7413.wav',\n",
       "  'text': 'Allied Arts had booked Marlene Dietrich into McCormick Place Dec. 8 and 9.',\n",
       "  'category': 'reviews'},\n",
       " {'id': 7414,\n",
       "  'file_path': 'dataset/part2/audios/audio_7414.wav',\n",
       "  'text': 'Something had to give.',\n",
       "  'category': 'reviews'},\n",
       " {'id': 7415,\n",
       "  'file_path': 'dataset/part2/audios/audio_7415.wav',\n",
       "  'text': 'Not La Dietrich.',\n",
       "  'category': 'reviews'},\n",
       " {'id': 7416,\n",
       "  'file_path': 'dataset/part2/audios/audio_7416.wav',\n",
       "  'text': 'Allied Arts then notified us that the Kirov would cut short its Los Angeles booking , fly here to open Nov. 28 , and close Dec. 2.',\n",
       "  'category': 'reviews'},\n",
       " {'id': 49858,\n",
       "  'file_path': 'dataset/part10/audios/audio_49858.wav',\n",
       "  'text': 'Calloused fingers , caressed only by the smoothness of polished rosaries , had swayed excitedly beneath puckered chins where tiny black hairs sprouted , never to be tweezed away.',\n",
       "  'category': 'romance'},\n",
       " {'id': 49859,\n",
       "  'file_path': 'dataset/part10/audios/audio_49859.wav',\n",
       "  'text': \"Mauve-colored mouths that had never known anything sweeter than the taste of new wine and the passion of man's tongue had not smiled , but had condemned again and again.\",\n",
       "  'category': 'romance'},\n",
       " {'id': 49860,\n",
       "  'file_path': 'dataset/part10/audios/audio_49860.wav',\n",
       "  'text': \"`` Puttana ''!!\",\n",
       "  'category': 'romance'},\n",
       " {'id': 49861,\n",
       "  'file_path': 'dataset/part10/audios/audio_49861.wav',\n",
       "  'text': 'But if the Old Man even thought about his wife now , nobody cared a fig.',\n",
       "  'category': 'romance'},\n",
       " {'id': 44312,\n",
       "  'file_path': 'dataset/part9/audios/audio_44312.wav',\n",
       "  'text': \"`` Come on , there's some cold chicken and we'll see what else ''.\",\n",
       "  'category': 'science_fiction'},\n",
       " {'id': 44313,\n",
       "  'file_path': 'dataset/part9/audios/audio_44313.wav',\n",
       "  'text': 'They went downstairs , loaded a tray lavishly.',\n",
       "  'category': 'science_fiction'},\n",
       " {'id': 44314,\n",
       "  'file_path': 'dataset/part9/audios/audio_44314.wav',\n",
       "  'text': \"`` Let's take it outside.\",\n",
       "  'category': 'science_fiction'},\n",
       " {'id': 44315,\n",
       "  'file_path': 'dataset/part9/audios/audio_44315.wav',\n",
       "  'text': \"It's plenty warm ''.\",\n",
       "  'category': 'science_fiction'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_path = 'samples-brown/sample_metadata.json'\n",
    "metadata = json.load(open(metadata_path))\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:28:06.869909Z",
     "iopub.status.busy": "2025-01-08T08:28:06.869605Z",
     "iopub.status.idle": "2025-01-08T08:28:09.787181Z",
     "shell.execute_reply": "2025-01-08T08:28:09.786498Z",
     "shell.execute_reply.started": "2025-01-08T08:28:06.869886Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B7_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B7_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b7_lukemelas-c5b4e57e.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b7_lukemelas-c5b4e57e.pth\n",
      "100%|██████████| 255M/255M [00:01<00:00, 228MB/s] \n"
     ]
    }
   ],
   "source": [
    "vision_model = models.efficientnet_b7(pretrained=True)\n",
    "vision_model.cuda()\n",
    "_ = vision_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:48:08.560322Z",
     "iopub.status.busy": "2025-01-08T08:48:08.559833Z",
     "iopub.status.idle": "2025-01-08T08:48:10.483766Z",
     "shell.execute_reply": "2025-01-08T08:48:10.483065Z",
     "shell.execute_reply.started": "2025-01-08T08:48:08.560276Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of HubertModel were not initialized from the model checkpoint at facebook/hubert-large-ls960-ft and are newly initialized: ['hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, HubertModel\n",
    "import soundfile as sf\n",
    "\n",
    "hubert_processor = AutoProcessor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "hubert_model = HubertModel.from_pretrained(\"facebook/hubert-large-ls960-ft\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:48:13.394417Z",
     "iopub.status.busy": "2025-01-08T08:48:13.394111Z",
     "iopub.status.idle": "2025-01-08T08:48:13.399963Z",
     "shell.execute_reply": "2025-01-08T08:48:13.398866Z",
     "shell.execute_reply.started": "2025-01-08T08:48:13.394393Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def hubert_audio_files(audio_file_list):\n",
    "    embeddings = []\n",
    "    for file_path in tqdm(audio_file_list):\n",
    "        # Use soundfile to read the audio file\n",
    "        data, samplerate = sf.read(file_path)\n",
    "        # Normalize the audio data\n",
    "        data = data / np.max(np.abs(data))\n",
    "        # Resample the audio to 16kHz\n",
    "        data = librosa.resample(data, orig_sr=samplerate, target_sr=16000)\n",
    "        # Convert the audio data to PyTorch tensor\n",
    "        audio = torch.from_numpy(data)\n",
    "        # Process the audio data with Hubert processor\n",
    "        inputs = hubert_processor(audio, sampling_rate=16000, return_tensors=\"pt\").to(device)\n",
    "        # Get the embeddings from Hubert model\n",
    "        with torch.no_grad():\n",
    "            hidden_states = hubert_model(**inputs).last_hidden_state\n",
    "            # avg_embedding = torch.mean(hidden_states.cpu(), dim=1)\n",
    "            # embeddings.append(avg_embedding.detach().numpy())\n",
    "            avg_embedding = torch.mean(hidden_states, dim=1)\n",
    "            embeddings.append(avg_embedding)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:48:20.418141Z",
     "iopub.status.busy": "2025-01-08T08:48:20.417807Z",
     "iopub.status.idle": "2025-01-08T08:48:24.355896Z",
     "shell.execute_reply": "2025-01-08T08:48:24.354989Z",
     "shell.execute_reply.started": "2025-01-08T08:48:20.418109Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:03<00:00, 16.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to get embeddings: 3.7080743312835693 seconds\n",
      "[tensor([[ 0.0905,  0.4490,  0.2590,  ..., -0.1822, -0.1710, -0.0982]],\n",
      "       device='cuda:0'), tensor([[ 0.1193,  0.3821,  0.1775,  ..., -0.1429, -0.2465, -0.1159]],\n",
      "       device='cuda:0'), tensor([[ 0.1381,  0.3855,  0.2234,  ..., -0.1220, -0.2374,  0.0386]],\n",
      "       device='cuda:0'), tensor([[ 0.1273,  0.4190,  0.2688,  ..., -0.1935, -0.1511,  0.0305]],\n",
      "       device='cuda:0'), tensor([[ 0.1165,  0.4030,  0.2201,  ..., -0.0851, -0.2520,  0.1198]],\n",
      "       device='cuda:0'), tensor([[ 0.0715,  0.3547,  0.2711,  ..., -0.0502, -0.3020, -0.0237]],\n",
      "       device='cuda:0'), tensor([[ 0.1156,  0.3867,  0.2429,  ..., -0.1749, -0.2486,  0.0530]],\n",
      "       device='cuda:0'), tensor([[ 0.2927,  0.4541,  0.2890,  ..., -0.1260, -0.1981,  0.1378]],\n",
      "       device='cuda:0'), tensor([[ 0.0771,  0.4343,  0.2171,  ..., -0.1285, -0.2518,  0.0061]],\n",
      "       device='cuda:0'), tensor([[ 0.2201,  0.3617,  0.1875,  ..., -0.2532, -0.1169,  0.0561]],\n",
      "       device='cuda:0'), tensor([[ 0.1751,  0.3422,  0.3274,  ..., -0.1135, -0.2647,  0.0715]],\n",
      "       device='cuda:0'), tensor([[ 0.2104,  0.4466,  0.2319,  ..., -0.2071, -0.1910,  0.0531]],\n",
      "       device='cuda:0'), tensor([[ 0.1458,  0.3890,  0.2303,  ..., -0.2174, -0.2147,  0.0191]],\n",
      "       device='cuda:0'), tensor([[ 0.1488,  0.3404,  0.2787,  ..., -0.0947, -0.2769,  0.0127]],\n",
      "       device='cuda:0'), tensor([[ 0.2198,  0.4938,  0.1886,  ..., -0.2036, -0.1833,  0.0342]],\n",
      "       device='cuda:0'), tensor([[ 0.1480,  0.3732,  0.3058,  ..., -0.1261, -0.2385,  0.0993]],\n",
      "       device='cuda:0'), tensor([[ 0.0740,  0.3830,  0.2493,  ..., -0.1294, -0.2483,  0.0358]],\n",
      "       device='cuda:0'), tensor([[ 0.0671,  0.3830,  0.1342,  ..., -0.1221, -0.3045,  0.0160]],\n",
      "       device='cuda:0'), tensor([[ 0.2062,  0.4075,  0.3246,  ..., -0.0791, -0.2233,  0.1603]],\n",
      "       device='cuda:0'), tensor([[ 0.0699,  0.3061,  0.2168,  ..., -0.1018, -0.2793,  0.0087]],\n",
      "       device='cuda:0'), tensor([[ 0.0406,  0.3263,  0.1505,  ..., -0.1318, -0.2910, -0.0364]],\n",
      "       device='cuda:0'), tensor([[ 0.0890,  0.3194,  0.2297,  ..., -0.1290, -0.2254, -0.0268]],\n",
      "       device='cuda:0'), tensor([[ 0.0935,  0.3499,  0.1800,  ..., -0.0455, -0.2378, -0.0756]],\n",
      "       device='cuda:0'), tensor([[ 0.2261,  0.4996,  0.2580,  ..., -0.2568, -0.1202,  0.0206]],\n",
      "       device='cuda:0'), tensor([[ 0.1243,  0.3678,  0.2091,  ..., -0.1461, -0.2525,  0.0267]],\n",
      "       device='cuda:0'), tensor([[ 0.1397,  0.3461,  0.2470,  ..., -0.1430, -0.2122,  0.0291]],\n",
      "       device='cuda:0'), tensor([[ 0.0819,  0.3192,  0.1970,  ..., -0.0904, -0.2553, -0.0107]],\n",
      "       device='cuda:0'), tensor([[ 0.1089,  0.4003,  0.1861,  ..., -0.1488, -0.2423,  0.0238]],\n",
      "       device='cuda:0'), tensor([[ 0.1711,  0.3873,  0.1992,  ..., -0.1858, -0.2388,  0.0304]],\n",
      "       device='cuda:0'), tensor([[ 0.1263,  0.3724,  0.2231,  ..., -0.1266, -0.2457,  0.0363]],\n",
      "       device='cuda:0'), tensor([[ 0.1296,  0.3889,  0.2402,  ..., -0.1590, -0.2260,  0.0527]],\n",
      "       device='cuda:0'), tensor([[ 0.1701,  0.3636,  0.2013,  ..., -0.1022, -0.1965,  0.0525]],\n",
      "       device='cuda:0'), tensor([[ 0.0670,  0.4381,  0.2327,  ..., -0.1665, -0.2581,  0.0323]],\n",
      "       device='cuda:0'), tensor([[ 0.2928,  0.3397,  0.2530,  ..., -0.2021, -0.1642,  0.0488]],\n",
      "       device='cuda:0'), tensor([[ 0.1210,  0.3134,  0.2501,  ..., -0.1595, -0.2633, -0.0202]],\n",
      "       device='cuda:0'), tensor([[ 0.1328,  0.3593,  0.2218,  ..., -0.1201, -0.2467,  0.0277]],\n",
      "       device='cuda:0'), tensor([[ 0.1011,  0.3733,  0.2573,  ..., -0.0953, -0.2635,  0.0624]],\n",
      "       device='cuda:0'), tensor([[ 0.1167,  0.3846,  0.2449,  ..., -0.0907, -0.2206,  0.0016]],\n",
      "       device='cuda:0'), tensor([[ 0.2366,  0.4484,  0.1871,  ..., -0.1932, -0.1463,  0.0313]],\n",
      "       device='cuda:0'), tensor([[ 0.1083,  0.3750,  0.1763,  ..., -0.1323, -0.2628,  0.0120]],\n",
      "       device='cuda:0'), tensor([[ 0.1176,  0.4357,  0.2302,  ..., -0.1855, -0.2422,  0.0721]],\n",
      "       device='cuda:0'), tensor([[ 0.1025,  0.3435,  0.2207,  ..., -0.1401, -0.2768,  0.0216]],\n",
      "       device='cuda:0'), tensor([[ 0.1145,  0.3954,  0.2416,  ..., -0.1077, -0.2369,  0.0049]],\n",
      "       device='cuda:0'), tensor([[ 0.1263,  0.3963,  0.1896,  ..., -0.1256, -0.2340,  0.0427]],\n",
      "       device='cuda:0'), tensor([[ 0.1582,  0.4406,  0.2489,  ..., -0.1833, -0.1673,  0.0525]],\n",
      "       device='cuda:0'), tensor([[ 0.1050,  0.2851,  0.1968,  ..., -0.1278, -0.2852,  0.0196]],\n",
      "       device='cuda:0'), tensor([[ 0.0609,  0.3863,  0.2278,  ..., -0.0876, -0.2461,  0.0082]],\n",
      "       device='cuda:0'), tensor([[ 0.0770,  0.3444,  0.1814,  ..., -0.1111, -0.2279, -0.0575]],\n",
      "       device='cuda:0'), tensor([[ 0.1276,  0.5122,  0.2195,  ..., -0.1185, -0.2372,  0.0676]],\n",
      "       device='cuda:0'), tensor([[ 0.2513,  0.4591,  0.1971,  ..., -0.1885, -0.2423,  0.0209]],\n",
      "       device='cuda:0'), tensor([[ 0.1352,  0.4360,  0.1434,  ..., -0.1349, -0.1838,  0.0316]],\n",
      "       device='cuda:0'), tensor([[ 0.1369,  0.4021,  0.2298,  ..., -0.1420, -0.2246,  0.0032]],\n",
      "       device='cuda:0'), tensor([[ 0.1786,  0.4943,  0.2546,  ..., -0.1704, -0.2191,  0.0509]],\n",
      "       device='cuda:0'), tensor([[ 0.0926,  0.3072,  0.2498,  ..., -0.0998, -0.2589,  0.0334]],\n",
      "       device='cuda:0'), tensor([[ 0.1165,  0.3601,  0.2283,  ..., -0.1522, -0.2447, -0.0058]],\n",
      "       device='cuda:0'), tensor([[ 0.0826,  0.3034,  0.2046,  ..., -0.1028, -0.2630, -0.0477]],\n",
      "       device='cuda:0'), tensor([[ 0.1461,  0.4279,  0.2095,  ..., -0.2235, -0.1898,  0.0073]],\n",
      "       device='cuda:0'), tensor([[ 0.1093,  0.4149,  0.2783,  ..., -0.1820, -0.2068, -0.0249]],\n",
      "       device='cuda:0'), tensor([[ 0.1492,  0.4057,  0.1682,  ..., -0.2288, -0.1653,  0.0263]],\n",
      "       device='cuda:0'), tensor([[ 0.1327,  0.3980,  0.1278,  ..., -0.1133, -0.1944,  0.0567]],\n",
      "       device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import time\n",
    "\n",
    "# List all .wav files in the samples-brown folder\n",
    "audio_file_list = glob.glob('samples-brown/*.wav')\n",
    "\n",
    "# Measure the time it takes to get embeddings\n",
    "start_time = time.time()\n",
    "embeddings = hubert_audio_files(audio_file_list)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken to get embeddings: {end_time - start_time} seconds\")\n",
    "# print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:34:40.950246Z",
     "iopub.status.busy": "2025-01-08T08:34:40.949528Z",
     "iopub.status.idle": "2025-01-08T08:34:40.955921Z",
     "shell.execute_reply": "2025-01-08T08:34:40.955008Z",
     "shell.execute_reply.started": "2025-01-08T08:34:40.950219Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:40:02.035319Z",
     "iopub.status.busy": "2025-01-08T08:40:02.035002Z",
     "iopub.status.idle": "2025-01-08T08:40:02.041428Z",
     "shell.execute_reply": "2025-01-08T08:40:02.040411Z",
     "shell.execute_reply.started": "2025-01-08T08:40:02.035299Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_image_embedding(path):\n",
    "    image = cv2.imread(path)\n",
    "    image_tensor = torch.from_numpy(image)\n",
    "    image_tensor = image_tensor.unsqueeze(0)\n",
    "    image_tensor = image_tensor.permute(0, 3, 1, 2)\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    image_tensor = image_tensor.float()\n",
    "    with torch.no_grad():\n",
    "        output = vision_model(image_tensor)\n",
    "        embedding = output[0].cpu()\n",
    "        return embedding\n",
    "\n",
    "def get_spectogram_embeddings_audio_files(audio_file_list):\n",
    "    embeddings = []\n",
    "    for file_path in tqdm(audio_file_list):\n",
    "        y, sr = librosa.load(file_path)\n",
    "        spec = librosa.stft(y)\n",
    "        spec_db = librosa.amplitude_to_db(abs(spec))\n",
    "        \n",
    "        plt.clf()\n",
    "        librosa.display.specshow(spec_db, x_axis='time', y_axis='log')\n",
    "        plt.xlabel('')\n",
    "        plt.ylabel('')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        saved_path = f'spec.png'\n",
    "        plt.savefig(saved_path, bbox_inches='tight', pad_inches=0)\n",
    "        image_embeddings = get_image_embedding(saved_path)\n",
    "        embeddings.append(image_embeddings)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:50:38.523416Z",
     "iopub.status.busy": "2025-01-08T08:50:38.523091Z",
     "iopub.status.idle": "2025-01-08T08:50:38.530264Z",
     "shell.execute_reply": "2025-01-08T08:50:38.529357Z",
     "shell.execute_reply.started": "2025-01-08T08:50:38.523391Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_image_embedding_batch(image_tensors):\n",
    "    image_tensors = image_tensors.to(device).float()\n",
    "    with torch.no_grad():\n",
    "        output = vision_model(image_tensors)\n",
    "    return output\n",
    "\n",
    "def get_spectogram_embeddings_audio_files(audio_file_list):\n",
    "    embeddings = []\n",
    "    image_tensors = []\n",
    "    \n",
    "    for file_path in tqdm(audio_file_list):\n",
    "        y, sr = librosa.load(file_path)\n",
    "        spec = librosa.stft(y)\n",
    "        spec_db = librosa.amplitude_to_db(abs(spec))\n",
    "        \n",
    "        plt.clf()\n",
    "        librosa.display.specshow(spec_db, x_axis='time', y_axis='log')\n",
    "        plt.xlabel('')\n",
    "        plt.ylabel('')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Convert the plot to a numpy array\n",
    "        plt_canvas = plt.gcf().canvas\n",
    "        plt_canvas.draw()\n",
    "        image = np.frombuffer(plt_canvas.tostring_rgb(), dtype=np.uint8)\n",
    "        image = image.reshape(plt_canvas.get_width_height()[::-1] + (3,))\n",
    "        \n",
    "        # Convert the numpy array to a tensor\n",
    "        image_tensor = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0)\n",
    "        image_tensors.append(image_tensor)\n",
    "    \n",
    "    # Stack all image tensors and get embeddings in batch\n",
    "    image_tensors = torch.cat(image_tensors, dim=0)\n",
    "    embeddings = get_image_embedding_batch(image_tensors)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:50:44.270371Z",
     "iopub.status.busy": "2025-01-08T08:50:44.270082Z",
     "iopub.status.idle": "2025-01-08T08:51:00.399929Z",
     "shell.execute_reply": "2025-01-08T08:51:00.399125Z",
     "shell.execute_reply.started": "2025-01-08T08:50:44.270349Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "embeddings2 = get_spectogram_embeddings_audio_files(audio_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:53:48.888784Z",
     "iopub.status.busy": "2025-01-08T08:53:48.888469Z",
     "iopub.status.idle": "2025-01-08T08:53:48.893949Z",
     "shell.execute_reply": "2025-01-08T08:53:48.893146Z",
     "shell.execute_reply.started": "2025-01-08T08:53:48.888760Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embeddings2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:53:49.838435Z",
     "iopub.status.busy": "2025-01-08T08:53:49.838145Z",
     "iopub.status.idle": "2025-01-08T08:53:49.843617Z",
     "shell.execute_reply": "2025-01-08T08:53:49.842847Z",
     "shell.execute_reply.started": "2025-01-08T08:53:49.838412Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:45:11.413339Z",
     "iopub.status.busy": "2025-01-08T08:45:11.412993Z",
     "iopub.status.idle": "2025-01-08T08:45:13.418818Z",
     "shell.execute_reply": "2025-01-08T08:45:13.417891Z",
     "shell.execute_reply.started": "2025-01-08T08:45:11.413310Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at facebook/hubert-large-ls960-ft were not used when initializing HubertForCTC: ['hubert.encoder.pos_conv_embed.conv.weight_g', 'hubert.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing HubertForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertForCTC were not initialized from the model checkpoint at facebook/hubert-large-ls960-ft and are newly initialized: ['hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## Hubert ASR\n",
    "from transformers import AutoProcessor, HubertForCTC\n",
    "import soundfile as sf\n",
    "\n",
    "hubert_processor = AutoProcessor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "hubert_model = HubertForCTC.from_pretrained(\"facebook/hubert-large-ls960-ft\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:45:34.612392Z",
     "iopub.status.busy": "2025-01-08T08:45:34.612078Z",
     "iopub.status.idle": "2025-01-08T08:45:34.617902Z",
     "shell.execute_reply": "2025-01-08T08:45:34.616924Z",
     "shell.execute_reply.started": "2025-01-08T08:45:34.612367Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def asr_hubert_audio_files(audio_file_list):\n",
    "    transcriptions = []\n",
    "#     audio_raws = []\n",
    "    for file_path in tqdm(audio_file_list):\n",
    "        # Use soundfile to read the audio file\n",
    "        data, samplerate = sf.read(file_path)\n",
    "        # Normalize the audio data\n",
    "        data = data / np.max(np.abs(data))\n",
    "        # Resample the audio to 16kHz\n",
    "        data = librosa.resample(data, orig_sr=samplerate, target_sr=16000)\n",
    "        # Convert the audio data to PyTorch tensor\n",
    "        audio = torch.from_numpy(data)\n",
    "        # Process the audio data with Hubert processor\n",
    "        inputs = hubert_processor(audio, sampling_rate=16000, return_tensors=\"pt\").to(device)\n",
    "        # Get the embeddings from Hubert model\n",
    "        with torch.no_grad():\n",
    "            logits = hubert_model(**inputs).logits\n",
    "            predicted_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            transcription = hubert_processor.batch_decode(predicted_ids)[0]\n",
    "            transcriptions.append(transcription.lower())\n",
    "#             audio_raws.append(audio)\n",
    "    return transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:45:52.257079Z",
     "iopub.status.busy": "2025-01-08T08:45:52.256743Z",
     "iopub.status.idle": "2025-01-08T08:45:56.398208Z",
     "shell.execute_reply": "2025-01-08T08:45:56.397238Z",
     "shell.execute_reply.started": "2025-01-08T08:45:52.257050Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:04<00:00, 14.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to get embeddings: 4.136927366256714 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "transcriptions = asr_hubert_audio_files(audio_file_list)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken to get embeddings: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:51:24.280195Z",
     "iopub.status.busy": "2025-01-08T08:51:24.279847Z",
     "iopub.status.idle": "2025-01-08T08:51:37.872606Z",
     "shell.execute_reply": "2025-01-08T08:51:37.871675Z",
     "shell.execute_reply.started": "2025-01-08T08:51:24.280169Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "text_model = SentenceTransformer('sentence-transformers/LaBSE').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:52:51.503458Z",
     "iopub.status.busy": "2025-01-08T08:52:51.503089Z",
     "iopub.status.idle": "2025-01-08T08:52:51.508888Z",
     "shell.execute_reply": "2025-01-08T08:52:51.507877Z",
     "shell.execute_reply.started": "2025-01-08T08:52:51.503428Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'something had to give'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriptions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:52:57.953625Z",
     "iopub.status.busy": "2025-01-08T08:52:57.953280Z",
     "iopub.status.idle": "2025-01-08T08:52:58.170312Z",
     "shell.execute_reply": "2025-01-08T08:52:58.169354Z",
     "shell.execute_reply.started": "2025-01-08T08:52:57.953594Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea80763d46eb4e3eb3ff42f61f315c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_embeddings = torch.Tensor(text_model.encode(transcriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:53:04.421762Z",
     "iopub.status.busy": "2025-01-08T08:53:04.421394Z",
     "iopub.status.idle": "2025-01-08T08:53:04.427282Z",
     "shell.execute_reply": "2025-01-08T08:53:04.426539Z",
     "shell.execute_reply.started": "2025-01-08T08:53:04.421732Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:54:10.960794Z",
     "iopub.status.busy": "2025-01-08T08:54:10.960444Z",
     "iopub.status.idle": "2025-01-08T08:54:10.967862Z",
     "shell.execute_reply": "2025-01-08T08:54:10.966786Z",
     "shell.execute_reply.started": "2025-01-08T08:54:10.960768Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HubertLabseConcat(nn.Module):\n",
    "    def __init__(self, in_features_text, in_features_image):\n",
    "        super(HubertLabseConcat, self).__init__()\n",
    "        self.image_seq = nn.Sequential(\n",
    "            nn.Linear(in_features_image, 768),\n",
    "            nn.BatchNorm1d(768),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.15),\n",
    "            nn.Linear(768, 576),\n",
    "            nn.BatchNorm1d(576),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(576, 768),\n",
    "        )\n",
    "        self.audio_seq = nn.Sequential(\n",
    "            nn.Linear(in_features_text, 768),\n",
    "            nn.BatchNorm1d(768),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.15),\n",
    "            nn.Linear(768, 576),\n",
    "            nn.BatchNorm1d(576),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(576, 768),\n",
    "        )\n",
    "        \n",
    "        self.mix_seq = nn.Sequential(\n",
    "            nn.Linear(2 * 768, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024, 800),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(800, 768),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x_audio, x_image):\n",
    "        x1 = self.audio_seq(x_audio)\n",
    "        x2 = self.image_seq(x_image)\n",
    "        concats = torch.cat((x1, x2), dim=1)\n",
    "        x = self.mix_seq(concats)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:57:50.667677Z",
     "iopub.status.busy": "2025-01-08T08:57:50.667327Z",
     "iopub.status.idle": "2025-01-08T08:57:50.701148Z",
     "shell.execute_reply": "2025-01-08T08:57:50.700254Z",
     "shell.execute_reply.started": "2025-01-08T08:57:50.667649Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-dd0c054c599d>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_to_test = torch.load(f'clasp.pt', map_location=device)\n"
     ]
    }
   ],
   "source": [
    "model_to_test = torch.load(f'clasp.pt', map_location=device)\n",
    "model_to_test = model_to_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:57:21.955683Z",
     "iopub.status.busy": "2025-01-08T08:57:21.955320Z",
     "iopub.status.idle": "2025-01-08T08:57:21.959734Z",
     "shell.execute_reply": "2025-01-08T08:57:21.958684Z",
     "shell.execute_reply.started": "2025-01-08T08:57:21.955651Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "embeddings = torch.stack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "embeddings2 = torch.stack(embeddings2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:59:01.986342Z",
     "iopub.status.busy": "2025-01-08T08:59:01.986046Z",
     "iopub.status.idle": "2025-01-08T08:59:02.017903Z",
     "shell.execute_reply": "2025-01-08T08:59:02.017209Z",
     "shell.execute_reply.started": "2025-01-08T08:59:01.986320Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to get embeddings: 0.027492523193359375 seconds\n"
     ]
    }
   ],
   "source": [
    "# Do not forget to normalize your spectogram and SSL embeddings before pass to fusion encoder for real inference.\n",
    "\n",
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    final_emb = model_to_test(embeddings, embeddings2)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken to get embeddings: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preform simple inference on the model using cosimilarity\n",
    "\n",
    "# Use the first text embedding as the sample\n",
    "sample_embedding = text_embeddings[0].unsqueeze(0).to(device)\n",
    "\n",
    "# Calculate cosine similarity between sample and all embeddings\n",
    "cos_sim = nn.CosineSimilarity(dim=1)\n",
    "similarities = cos_sim(sample_embedding, final_emb)\n",
    "\n",
    "# Find the index of most similar embedding\n",
    "most_similar_idx = torch.argmax(similarities).item()\n",
    "\n",
    "print(f\"Most similar embedding index: {most_similar_idx}\")\n",
    "print(f\"Cosine similarity: {similarities[most_similar_idx].item():.4f}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
